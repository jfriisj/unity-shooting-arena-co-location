@inproceedings{SchildJonas2018E—Ev,
abstract = {Conference Title: 2018 IEEE 6th International Conference on Serious Games and Applications for Health (SeGAH) Conference Start Date: 2018, May 16 Conference End Date: 2018, May 18 Conference Location: Vienna, Austria An anaphylactic shock constitutes a representative scenario for critical paramedical cases that happen too rare to eventually occur within a regular curricular term of vocational training. As a possible solution, this paper presents EPICSAVE, a development case that yields novel training tools using multi-user virtual reality (VR) and serious game methodology. The case describes the interdisciplinary setup and iterative workflow of the development of a simulation prototype. Examples show design tools and methodologies, e.g., finding focus in medical treatment. Results from two pilot studies indicate that specifically multi-user VR may enhance paramedic training. The subsequently developed prototype offers collaborative training for two paramedic trainees and one trainer. Results from a user study with paramedic trainees indicate that experiencing a positive VR training outcome depends on high presence effects and is limited by usability issues. We provide a list of open design and usability issues that shall help to improve future integration of multi-user VR in training facilities.},
author = {Schild, Jonas and Lerner, Dieter and Misztal, Sebastian and Luiz, Thomas},
address = {Piscataway},
booktitle = {The Institute of Electrical and Electronics Engineers, Inc. (IEEE) Conference Proceedings},
copyright = {Copyright The Institute of Electrical and Electronics Engineers, Inc. (IEEE) 2018},
keywords = {Health services ;  Pilot training ;  Training ;  Usability ;  Virtual reality ;  Workflow},
language = {eng},
pages = {1-},
publisher = {The Institute of Electrical and Electronics Engineers, Inc. (IEEE)},
title = {EPICSAVE — Enhancing vocational training for paramedics with multi-user virtual reality},
year = {2018},
}

@article{ReimerDennis2021CfSV,
abstract = {In colocated multi-user Virtual Reality applications, relative user positions in the virtual environment need to match their relative positions in the physical tracking space. A mismatch between virtual and real relative user positions might lead to harmful events such as physical user collisions. This paper examines three calibration methods that enable colocated Virtual Reality scenarios for SLAM-tracked head-mounted displays without the need for an external tracking system. Two of these methods—fixed-point calibration and marked-based calibration—have been described in previous research; the third method that uses hand tracking capabilities of head-mounted displays is novel. We evaluated the accuracy of these three methods in an experimental procedure with two colocated Oculus Quest devices. The results of the evaluation show that our novel hand tracking-based calibration method provides better accuracy and consistency while at the same time being easy to execute. The paper further discusses the potential of all evaluated calibration methods.},
author = {Reimer, Dennis and Podkosova, Iana and Scherzer, Daniel and Kaufmann, Hannes},
address = {Basel},
copyright = {Copyright 2021 Elsevier B.V., All rights reserved.},
issn = {2073-431X},
journal = {Computers (Basel)},
keywords = {Multi-user VR ;  Accuracy ;  Calibration ;  Cameras ;  Colocation ;  Displays ;  Evaluation ;  Hand tracking ;  Helmet mounted displays ;  Methods ;  Shared space ;  Tracking systems ;  User experience ;  Virtual environments ;  Virtual reality},
language = {eng},
number = {5},
pages = {58-},
publisher = {MDPI AG},
title = {Colocation for SLAM-Tracked VR Headsets with Hand Tracking},
volume = {10},
year = {2021},
}

@incollection{SharmaSharad2025IASR,
abstract = {There is a critical need to improve emergency response, decision-making, and safety for the most critical threats to public spaces today. Active shooter events are one of the most critical threats that require training for high-pressure decisions that need to be made during such situations. This paper presents the prototype of an immersive active shooter response training and decision-making environment for a university campus building. The immersive active shooter response training environment is developed in Unity 3D and is based on run, hide, and fight modes for emergency response. We have presented a multi-user virtual reality (VR) platform where experiments for active shooter response can be conducted using computer-controlled (AI) agents and user-controlled agents. This platform can be used as a teaching and educational tool for navigation and performing VR evacuation drills for active shooter events. A user study was conducted to evaluate the immersive VR training environment with 195 participants. The experiment sought to examine how the proposed tool influenced participants’ understanding of the safest actions to take during an active shooter situation. The evaluation includes Group Environment Questionnaire (GEQ), Presence Questionnaire (PQ), System Usability Scale (SUS), and Technology Acceptance Model (TAM) Questionnaire. The findings suggest that the participants’ knowledge, intrinsic motivation, and self-efficacy showed a significant increase immediately after the training. The results show that the majority of users agreed that the sense of presence was increased when using the immersive emergency response training environment for an active shooter evacuation environment. Through the use of an immersive VR platform, trainees develop a heightened sense of spatial awareness and an understanding of how to navigate the building in high-stress situations, thus increasing the chances of survival and successful evacuation.},
author = {Sharma, Sharad and Moses, Pranav Abishai and Fragomeni, Gino and Chen, Jessie Y. C.},
address = {Cham},
booktitle = {VIRTUAL, AUGMENTED AND MIXED REALITY, VAMR 2025, PT III},
copyright = {The Author(s), under exclusive license to Springer Nature Switzerland AG 2025},
isbn = {9783031937149},
issn = {0302-9743},
keywords = {building evacuation ;  Computer Science ;  Computer Science Cybernetics ;  Computer Science Interdisciplinary Applications ;  Computer Science Theory & Methods ;  immersive VR ;  Science & Technology ;  Technology ;  training simulation ;  Virtual reality},
language = {eng},
pages = {220-232},
publisher = {Springer Nature Switzerland},
series = {Lecture Notes in Computer Science},
title = {Immersive Active Shooter Response Training and Decision-Making Environment for a University Campus Building},
volume = {15790},
year = {2025},
}

@inproceedings{SameriMohammadJavad2024CciV,
abstract = {The future of human interaction is virtual. Thus it will require effective collaboration on tasks among users in remote settings. eXtended Reality (XR) is playing a leading role in this transition, offering a realm where virtual collaboration becomes not just possible but essential in situations where physical presence is limited by risk, cost, or complexity. However, while networks are continuously evolving, they can still introduce unexpected impairments that potentially degrade the user perception, i.e., the Quality-of-Experience (QoE), of such Collaborative Virtual Reality (CVR) scenarios. In response to this challenge, this paper presents a demonstrator designed to explicitly showcase the effects of network conditions on CVR. Our platform, centered around a pizza-making game, allows for exploration of the real-time impact of different network parameters, such as packet delay, loss, and throttling on the user engagement and perception in CVR. The framework employs a combination of subjective, objective, and physiological assessments, including the capture of heart rate and skin conductivity, to gain comprehensive insights into user experiences. Our platform not only allows users to directly experience the impact of network impairments on CVR interactions but also provides initial evidence of how such distortions affect both subjective perceptions and objective performance metrics.},
author = {Sameri, Mohammad Javad and Van Damme, Sam and Schwarzmann, Susanna and Wei, Qing and Trivisonno, Riccardo and De Turck, Filip and Torres Vega, Maria},
copyright = {info:eu-repo/semantics/openAccess},
keywords = {Collaborative Virtual Reality ;  human-computer interaction ;  Network Impairments ;  Quality of Experience ;  REALITY ;  Technology and Engineering},
language = {eng},
publisher = {Association for Computing Machinery (ACM)},
title = {Collaborative cooking in VR : effects of network distortion in multi-user virtual environments},
year = {2024},
}

@article{ParkSuyeon2023EoAS,
abstract = {Many researchers have introduced Virtual Reality (VR) systems for various medical applications, such as training, education, and collaboration. In this research, we explore the effect of using 3-second sketch communication cue in a collaborative VR system for two surgeons planning surgery, when a head-gaze pointer and hand-gesture are available as the baseline cues. We defined five steps of surgical planning for a liver cancer, based on the proposal from surgeons, and conducted a user study with the task including the five steps. The results demonstrated that the 3-second sketch cue increased the level of usability and message understanding between two collaborators, and decreased the required task load. Additionally, we propose six design principles for the interface of a surgical planning VR system. First, a 3D reconstructed body model should be supported based on real-world data, such as CT and MRI images. Second, the cross-sectional view at any angle and position should be supported for examining inside the body and organs. Third, visual communication cues, such as sketches, pointers, and hand gestures, are crucial for communication. Fourth, the erasing sketch should occur when the next sketch starts being drawn. Fifth, the system should support permanent annotations, especially attached to the 3D body, together with the volatile visual communication cues, such as hand gesture, erased sketch, and head-gaze pointer. Sixth, when both collaborators focus on the same object or area, the system should control the transparency of the hand gestures and head-gaze pointers to mitigate the effect of occlusions.},
author = {Park, Suyeon and Suh, Gayun and Kim, Soo-Hyong and Yang, Hyung-Jung and Lee, Gun and Kim, Seungwon},
issn = {2169-3536},
journal = {IEEE access},
keywords = {Collaboration ;  DICOM ;  Planning ;  Surgery ;  surgical planning ;  Task analysis ;  Three-dimensional displays ;  Virtual reality ;  virtual reality (VR) ;  Visual communication ;  visual communication cue},
language = {eng},
pages = {1-1},
publisher = {IEEE},
title = {Effect of Auto-Erased Sketch Cue in Multiuser Surgical Planning Virtual Reality with Various Visual Communication Cues},
year = {2023},
}

@article{HeinonenHanna2022EtBo,
abstract = {Technical documentation creation is a collaborative process involving several departments in R&D. Even though virtual reality (VR) has been demonstrated to facilitate industrial collaboration and advance the product development lifecycle in earlier studies, it has not been utilized for technical documentation review and risk assessment processes in industrial companies. This article presents a case study where the benefits of VR to maintenance documentation reviews and risk assessments were studied. The virtual reality environment was tested by nine domain experts from an industrial company in a user study that replicated their actual real-life industrial collaboration tasks. Both qualitative and quantitative data were collected during the study. Our findings show that collaborative VR has the potential to enhance the documentation review and risk assessment processes. Overall, the concept of using virtual reality for documentation review and risk assessment processes was rated positively by participants, and even though further development is needed for the review tools, VR was viewed as a concept that facilitates collaboration, enhances the current review practices, and increases spatial understanding. The benefits of VR are evident, especially for geographically scattered teams that rarely meet face-to-face or do not have access to the actual physical equipment. In cases where traditional means of communication are not enough, process improvements are needed for documentation review and risk assessment processes, and our proposed solution is VR.},
author = {Heinonen, Hanna and Burova, Alisa and Siltanen, Sanni and Lähteenmäki, Jussi and Hakulinen, Jaakko and Turunen, Markku},
address = {BASEL},
copyright = {Copyright 2022 Elsevier B.V., All rights reserved.},
issn = {2076-3417},
journal = {Applied sciences},
keywords = {collaborative VR ;  Chemistry ;  Chemistry Multidisciplinary ;  Collaboration ;  COVID-19 ;  Engineering ;  Engineering Multidisciplinary ;  industrial maintenance ;  maintenance method development ;  Materials Science ;  Materials Science Multidisciplinary ;  Physical Sciences ;  Physics ;  Physics Applied ;  Product development ;  risk assessment ;  Science & Technology ;  technical documentation ;  Technology ;  Virtual reality},
language = {eng},
number = {14},
pages = {7155-},
publisher = {Mdpi},
title = {Evaluating the Benefits of Collaborative VR Review for Maintenance Documentation and Risk Assessment},
volume = {12},
year = {2022},
}

@article{ChenLei2024Eoep,
abstract = {Exocentric views play a pivotal role in computer-mediated collaboration, especially in Collaborative Virtual Environments (CVEs), where focusing on the actions and operations of collaboration partners is crucial. The exocentric perspective offers users a vantage point to ascertain the whereabouts and actions of their partners, enhancing spatial awareness and social presence in CVEs. Moreover, interacting via the Exocentric Perspective Interface (ExPI) can help users complete searching and manipulation tasks remotely and efficiently. This work investigates the potential benefits of two representative ExPIs, World In Miniature (WIM) and 2D Map, for VR collaboration. We conducted a user study with 36 participants (18 pairs) to compare WIM and the 2D Map against a baseline in a VR collaborative task encompassing a series of searching and manipulation tasks with different task complexities (Simple, Medium, and Complex). For the Baseline (BL) condition, participants were not provided with an Exocentric Perspectives Interface (ExPI) but instead were given a map of the virtual environment (VE). The results indicate that these two ExPIs significantly improved task performance, usability, social presence, and user experience while reducing VR sickness. In addition, we also found that WIM outperformed 2D Maps, especially in complex collaborative environments. Based on the findings, three design implications are proposed to guide the design of future VR collaboration systems.
•Exocentric perspective interfaces can improve collaboration in VR environments.•World In Miniature (WIM) and 2D Map can improve efficiency and usability.•WIM surpasses 2D Maps in complex collaborative taks in VR.•Our findings lead to a set of design implications for future collaborative VR systems.},
author = {Chen, Lei and Long, Junkun and Shi, Rongkai and Li, Ziming and Yue, Yong and Yu, Lingyun and Liang, Hai-Ning},
address = {AMSTERDAM},
copyright = {2024},
issn = {0141-9382},
journal = {Displays},
keywords = {Collaborative and social computing ;  Computer Science ;  Computer Science Hardware & Architecture ;  Engineering ;  Engineering Electrical & Electronic ;  Instruments & Instrumentation ;  Interface design ;  Optics ;  Physical Sciences ;  Science & Technology ;  Technology ;  User studies ;  Virtual reality ;  World-in-miniature},
language = {eng},
pages = {102781-},
publisher = {Elsevier B.V},
title = {Exploration of exocentric perspective interfaces for virtual reality collaborative tasks},
volume = {84},
year = {2024},
}

@article{VanDammeSam2024IoLo,
abstract = {Interactive, multi-user experiences are meant to define the present and future of Virtual Reality (VR). Such immersive experiences will typically consist of remote collaborations where content is streamed and/or synchronized over a network connection. Thus, real-time collaboration will be key. In this light, the responsiveness of the system and the network will define the overall experience. As such, understanding the effect of network distortions, especially related to time delay, on end-user’s perception (in terms of Quality-of-Experience (QoE)), performance, and collaboration becomes crucial. The existing literature, however, has mostly focused on network requirements from a system point-of-view, where the key performance parameters are only provided in the form of Quality-of-Service (QoS) parameters (such as end-to-end latency). However, the translation of these network impairments to the end-user experience is often omitted. The purpose of this paper is to fill the gap by providing a thorough investigation of the impact of latency on the perception of users while performing collaborative tasks in multi-user VR. To this end, an experimental framework was designed, developed, and tested. It is based on a multi-device synchronizing architecture, enabling two simultaneous users to work together in a gamified virtual environment. The developed test environment also allows for the identification of the most prominent network requirements and objective analysis for each traffic link. To experimentally investigate the impact of latency on user perception, a user study was conducted. Participants were paired and asked to perform the collaborative task under different latency-prone scenarios. The results show that users are able to easily distinguish between distorted and non-distorted network configurations. However, making a distinction between different manifestations of latency is much less straightforward. Moreover, factors such as the user’s role in the experience and the required task, and the level of interactivity and movement have an important influence on the subjective level of perception, the strength of the user’s preferences, and the occurrence of cybersickness. In contrast, no significant differences in objective metrics, such as system performance and user completion time were observed. These results can support the creation of collective QoE metrics that model the group as a whole rather than each individual separately. As such, this work provides an important step to dynamically counteract any drops in group dynamics and performance by means of smart interventions in the transmission system and/or virtual environment.},
author = {Van Damme, Sam and Sameri, Javad and Schwarzmann, Susanna and Wei, Qing and Trivisonno, Riccardo and De Turck, Filip and Torres Vega, Maria},
address = {BASEL},
copyright = {Copyright 2024 Elsevier B.V., All rights reserved.},
issn = {2076-3417},
journal = {Applied sciences},
keywords = {collaborative VR ;  Analysis ;  Architecture ;  Chemistry ;  Chemistry Multidisciplinary ;  Collaboration ;  Engineering ;  Engineering Multidisciplinary ;  interactivity ;  latency ;  Materials Science ;  Materials Science Multidisciplinary ;  network impairments ;  Physical Sciences ;  Physics ;  Physics Applied ;  QoE ;  Science & Technology ;  Technology ;  User experience ;  Virtual reality},
language = {eng},
number = {6},
pages = {2290-},
publisher = {Mdpi},
title = {Impact of Latency on QoE, Performance, and Collaboration in Interactive Multi-User Virtual Reality},
volume = {14},
year = {2024},
}

@article{WeissYannick2025ItEo,
abstract = {Our sense of touch plays a crucial role in physical collaboration, yet rendering realistic haptic feedback in collaborative extended reality (XR) remains a challenge. Co-located XR systems predominantly rely on prefabricated passive props that provide high-fidelity interaction but offer limited adaptability. Haptic Illusions (HIs), which leverage multisensory integration, have proven effective in expanding haptic experiences in single-user contexts. However, their role in XR collaboration has not been explored. To examine the applicability of HIs in multi-user scenarios, we conducted an experimental user study (N=30) investigating their effect on a collaborative object handover task in virtual reality. We manipulated visual shape and size individually and analyzed their impact on users' performance, experience, and behavior. Results show that while participants adapted to the illusions by shifting sensory reliance and employing specific sensorimotor strategies, visuo-haptic mismatches reduced both performance and experience. Moreover, mismatched visualizations in asymmetric user roles negatively impacted performance. Drawing from these findings, we provide practical guidelines for incorporating HIs into collaborative XR, marking a first step toward richer haptic interactions in shared virtual spaces.},
author = {Weiss, Yannick and Rasch, Julian and Fischer, Jonas and Muller, Florian},
address = {United States},
issn = {1077-2626},
journal = {IEEE transactions on visualization and computer graphics},
keywords = {Collaboration ;  Extended reality ;  Handover ;  Hands ;  haptic illusions ;  Haptic interfaces ;  multi-user collaboration ;  Rendering (computer graphics) ;  Shape ;  Training ;  User experience ;  virtual and extended reality ;  Visualization},
language = {eng},
pages = {1-11},
publisher = {IEEE},
title = {Investigating the Effects of Haptic Illusions in Collaborative Virtual Reality},
volume = {PP},
year = {2025},
}

@article{LiuXiaolong2024MGFf,
abstract = {Object manipulation is a fundamental interaction in virtual reality (VR). Efficient and accurate manipulation is important for many VR applications, especially collaborative VR applications. We introduce a collaborative method based on the manipulation guidance field (MGF) to improve manipulation accuracy and efficiency. MGF aims to guide users of different manipulation types to different manipulation viewpoints to efficiently and collaboratively manipulate objects. First, we introduce the concept of MGF and its construction method. Two strategies are offered to accelerate the MGF updating process. A collaborative manipulation method to manipulate objects using the guidance of MGF is then proposed. Finally, a user study (n = 36 participants) was conducted to evaluate the efficiency and accuracy of our MGF-based collaborative object manipulation method in three scenes: (1) Livingroom scene; (2) WaveHouse scene; (3) Pipe scene. Compared to a control method without MGF, the results show that our MGF-based method has significantly reduced task completion time, position error, rotation error, and task load.},
author = {Liu, Xiaolong and Wang, Lili and Luan, Shuai},
address = {PHILADELPHIA},
copyright = {2023 Taylor & Francis Group, LLC 2023},
issn = {1044-7318},
journal = {International journal of human-computer interaction},
keywords = {Collaboration ;  Completion time ;  Computer Science ;  Computer Science Cybernetics ;  Control methods ;  Engineering ;  Ergonomics ;  guiding field ;  human-computer interaction ;  object manipulation ;  Position errors ;  Science & Technology ;  Taskload ;  Technology ;  Virtual reality},
language = {eng},
number = {21},
pages = {6776-6792},
publisher = {Taylor & Francis},
title = {Manipulation Guidance Field for Collaborative Object Manipulation in VR},
volume = {40},
year = {2024},
}

@article{LiuQiaoxi2021SVRP,
abstract = {As virtual reality (VR) headsets become more commercially accessible, a range of social platforms have been developed that exploit the immersive nature of these systems. There is a growing interest in using these platforms in social and work contexts, but relatively little work into examining the usability choices that have been made. We developed a usability inspection method based on cognitive walkthrough that we call
guided group walkthrough
. Guided group walkthrough is applied to existing social VR platforms by having a guide walk the participants through a series of abstract social tasks that are common across the platforms. Using this method we compared six social VR platforms for the Oculus Quest. After constructing an appropriate task hierarchy and walkthrough question structure for social VR, we ran several groups of participants through the walkthrough process. We undercover usability challenges that are common across the platforms, identify specific design considerations and comment on the utility of the walkthrough method in this situation.},
author = {Liu, Qiaoxi and Steed, Anthony},
copyright = {Copyright 2022 Elsevier B.V., All rights reserved.},
issn = {2673-4192},
journal = {Frontiers in virtual reality},
keywords = {collaborative virtual environment ;  cognitive walkthrough ;  consumer virtual reality ;  social virtual reality ;  usability inspection methods},
language = {eng},
publisher = {Frontiers Media S.A},
title = {Social Virtual Reality Platform Comparison and Evaluation Using a Guided Group Walkthrough Method},
volume = {2},
year = {2021},
}